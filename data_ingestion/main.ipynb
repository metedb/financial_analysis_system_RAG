{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading, processing, and saving various financial data to PostgreSQL and MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Stock Data via yfinance API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def get_stock_data(tickers, period=\"1y\", interval=\"1d\"):\n",
    "    combined_data = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            company_name = stock.info.get('longName', ticker)\n",
    "            \n",
    "            # get historical data for a custom period with specified intervals\n",
    "            stock_data = await asyncio.to_thread(stock.history, period=period, interval=interval)\n",
    "            \n",
    "            # basic identifiers for data\n",
    "            stock_data['Ticker'] = ticker\n",
    "            stock_data['Company_Name'] = company_name\n",
    "            \n",
    "            # calculate additional metrics to store\n",
    "            stock_data['Daily_Return'] = stock_data['Close'].pct_change() * 100\n",
    "            stock_data['Trading_Range'] = stock_data['High'] - stock_data['Low']\n",
    "            stock_data['Volume_Ratio'] = stock_data['Volume'].pct_change() + 1\n",
    "            \n",
    "            # adding time context\n",
    "            stock_data['Trading_Day'] = stock_data.index.day_name()\n",
    "            stock_data['Trading_Month'] = stock_data.index.month_name()\n",
    "            stock_data['Trading_Quarter'] = 'Q' + stock_data.index.quarter.astype(str)\n",
    "            stock_data['Trading_Year'] = stock_data.index.year\n",
    "            \n",
    "            # fill NaN values\n",
    "            stock_data['Daily_Return'] = stock_data['Daily_Return'].fillna(0)\n",
    "            stock_data['Volume_Ratio'] = stock_data['Volume_Ratio'].fillna(1)\n",
    "            \n",
    "            # rounding columns\n",
    "            numerical_columns = ['Open', 'High', 'Low', 'Close', 'Daily_Return', 'Trading_Range', 'Volume_Ratio']\n",
    "            stock_data[numerical_columns] = stock_data[numerical_columns].round(2)\n",
    "            \n",
    "            ## success message\n",
    "            combined_data.append(stock_data)\n",
    "            print(f\"Successfully processed {ticker} ({company_name})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    final_df = pd.concat(combined_data, axis=0)\n",
    "    final_df = final_df.reset_index()\n",
    "    final_df['Date'] = final_df['Date'].dt.strftime('%B %d, %Y')\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-News articles and summaries via Alpha Vantage API, focused on specific companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\"\"\"\n",
    "Fetches news sentiment data for a given ticker from Alpha Vantage using their API\n",
    "Handles API limits by checking for \"Note\" in the response\n",
    "Parses and returns feed data along with a timestamp if the request is successful\n",
    "\"\"\"\n",
    "async def get_news_company(session, api_key, ticker):\n",
    "    \"\"\"Fetch news data for a single ticker from Alpha Vantage.\"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={ticker}&apikey={api_key}\" \n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                \n",
    "                # check for API limit message\n",
    "                if \"Note\" in data:\n",
    "                    print(f\"API limit reached: {data['Note']}\")\n",
    "                    return None\n",
    "    \n",
    "                return {\n",
    "                    'ticker': ticker,\n",
    "                    'feed': data.get('feed', []),\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Error fetching data for {ticker}: Status {response.status}\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception while fetching {ticker}: {str(e)}\")\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-News articles and summaries via Alpha Vantage API, focused on specific industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fetches news sentiment data for a given industry/sector from Alpha Vantage using their API\n",
    "Handles API limits by checking for \"Note\" in the response\n",
    "Parses and returns feed data along with a timestamp if the request is successful\n",
    "\"\"\"\n",
    "\n",
    "async def get_news_industry(session, api_key, topic):\n",
    "    url = f\"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&topics={topic}&apikey={api_key}\"\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                \n",
    "                # check for API limit message\n",
    "                if \"Note\" in data:\n",
    "                    print(f\"API limit reached: {data['Note']}\")\n",
    "                    return None\n",
    "                    \n",
    "                return {\n",
    "                    'topic': topic,\n",
    "                    'feed': data.get('feed', []),\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Error fetching data for {topic}: Status {response.status}\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception while fetching {topic}: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Financial Statements via yfinance API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "-Processes financial data for each ticker using the Yahoo Finance API\n",
    "-Retrieves and cleans quarterly and financial data\n",
    "-Adds key financial metrics such as Net Margin, Revenue QoQ, and Operating Margin\n",
    "-Extracts fiscal periods (quarter and year) from the data index for better temporal analysis\n",
    "\"\"\"\n",
    "async def get_company_financials(tickers):\n",
    "    quarterly_data = []\n",
    "    annual_data = []\n",
    "    metrics_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            company = yf.Ticker(ticker)\n",
    "            company_name = company.info.get('longName', ticker)\n",
    "            print(f\"Processing {company_name} ({ticker})\")\n",
    "            \n",
    "            quarterly = company.quarterly_financials\n",
    "            if not quarterly.empty:\n",
    "                quarterly_df = quarterly.T\n",
    "                quarterly_df['Company_Name'] = company_name\n",
    "                quarterly_df['Report_Type'] = 'Quarterly'\n",
    "                \n",
    "                if 'Total Revenue' in quarterly_df.columns and 'Net Income' in quarterly_df.columns:\n",
    "                    quarterly_df['Net_Margin'] = (quarterly_df['Net Income'] / quarterly_df['Total Revenue']).round(4)\n",
    "                \n",
    "                if 'Total Revenue' in quarterly_df.columns:\n",
    "                    quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
    "                \n",
    "                if 'Operating Income' in quarterly_df.columns and 'Total Revenue' in quarterly_df.columns:\n",
    "                    quarterly_df['Operating_Margin'] = (quarterly_df['Operating Income'] / quarterly_df['Total Revenue']).round(4)\n",
    "                \n",
    "                quarterly_df['Fiscal_Quarter'] = quarterly_df.index.quarter\n",
    "                quarterly_df['Fiscal_Year'] = quarterly_df.index.year\n",
    "                \n",
    "                quarterly_data.append(quarterly_df)\n",
    "            \n",
    "            annual = company.financials\n",
    "            if not annual.empty:\n",
    "                annual_df = annual.T\n",
    "                annual_df['Company_Name'] = company_name\n",
    "                annual_df['Report_Type'] = 'Annual'\n",
    "                \n",
    "                if 'Total Revenue' in annual_df.columns and 'Net Income' in annual_df.columns:\n",
    "                    annual_df['Net_Margin'] = (annual_df['Net Income'] / annual_df['Total Revenue']).round(4)\n",
    "                \n",
    "                if 'Total Revenue' in annual_df.columns:\n",
    "                    annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n",
    "                \n",
    "                if 'Operating Income' in annual_df.columns and 'Total Revenue' in annual_df.columns:\n",
    "                    annual_df['Operating_Margin'] = (annual_df['Operating Income'] / annual_df['Total Revenue']).round(4)\n",
    "                \n",
    "                annual_df['Fiscal_Year'] = annual_df.index.year\n",
    "                \n",
    "                annual_data.append(annual_df)\n",
    "            \n",
    "            info = company.info\n",
    "            metrics = {\n",
    "                'Company_Name': company_name,\n",
    "                'PE_Ratio': info.get('forwardPE'),\n",
    "                'Trailing_PE': info.get('trailingPE'),\n",
    "                'Profit_Margin': info.get('profitMargins'),\n",
    "                'Revenue_Growth': info.get('revenueGrowth'),\n",
    "                'ROE': info.get('returnOnEquity'),\n",
    "                'ROA': info.get('returnOnAssets'),\n",
    "                'Debt_To_Equity': info.get('debtToEquity'),\n",
    "                'Current_Ratio': info.get('currentRatio'),\n",
    "                'Quick_Ratio': info.get('quickRatio'),\n",
    "                'Market_Cap': info.get('marketCap'),\n",
    "                'Enterprise_Value': info.get('enterpriseValue'),\n",
    "                'EV_To_Revenue': info.get('enterpriseToRevenue'),\n",
    "                'EV_To_EBITDA': info.get('enterpriseToEbitda'),\n",
    "                'Dividend_Yield': info.get('dividendYield'),\n",
    "                'Payout_Ratio': info.get('payoutRatio'),\n",
    "                'Beta': info.get('beta'),\n",
    "                'Date': pd.Timestamp.now()\n",
    "            }\n",
    "            metrics_data.append(pd.DataFrame([metrics]))\n",
    "            \n",
    "            print(f\"Successfully processed {company_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    result = {\n",
    "        'quarterly': pd.concat(quarterly_data) if quarterly_data else pd.DataFrame(),\n",
    "        'annual': pd.concat(annual_data) if annual_data else pd.DataFrame(),\n",
    "        'metrics': pd.concat(metrics_data) if metrics_data else pd.DataFrame()\n",
    "    }\n",
    "    \n",
    "    for key in result:\n",
    "        if not result[key].empty:\n",
    "            result[key] = result[key].round(4)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>To-do: Adding currency rates and social media sentiment download functions<mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-MAIN DOWNLOAD FUNCTION (will be updated for cleaner code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# setting up PostgreSQL connection\n",
    "postgres_url = \"postgresql://postgres:password123@localhost:5432/postgres\"\n",
    "postgres_engine = create_engine(postgres_url)\n",
    "\n",
    "# setting up MongoDB connection\n",
    "mongo_client = MongoClient('mongodb://localhost:27017/')\n",
    "mongo_db = mongo_client['financial_data']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Download comprehensive financial data and save to:\n",
    "1. Local files\n",
    "2. PostgreSQL (tabular financial data)\n",
    "3. MongoDB (news data)\n",
    "\"\"\"\n",
    "async def download_financial_data(api_key, tickers, topics, period=\"1y\", interval=\"1d\"):\n",
    "    data_dir = \"/Users/metedibi/Desktop/LLM_STUDIES/novus_case_study/financial_data\"\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    all_news = []\n",
    "    calls_made = 0\n",
    "    \n",
    "    # 1. Stock data\n",
    "    print(\"Fetching stock data...\")\n",
    "    stock_data = await get_stock_data(tickers, period, interval)\n",
    "    # Save to local file\n",
    "    stock_file = os.path.join(data_dir, \"stock_data.csv\")\n",
    "    stock_data.to_csv(stock_file)\n",
    "    # Save to PostgreSQL\n",
    "    stock_data.to_sql(\"stock_data\", postgres_engine, if_exists=\"replace\", index=False)\n",
    "    print(f\"Saved stock data to {stock_file} and PostgreSQL\")\n",
    "\n",
    "    # 2. Company financials\n",
    "    print(\"Fetching company financials...\")\n",
    "    financial_data = await get_company_financials(tickers)\n",
    "    # Save to local files\n",
    "    quarterly_file = os.path.join(data_dir, \"quarterly_financials.csv\")\n",
    "    annual_file = os.path.join(data_dir, \"annual_financials.csv\")\n",
    "    metrics_file = os.path.join(data_dir, \"financial_metrics.csv\")\n",
    "    financial_data['quarterly'].to_csv(quarterly_file)\n",
    "    financial_data['annual'].to_csv(annual_file)\n",
    "    financial_data['metrics'].to_csv(metrics_file)\n",
    "    # Save to PostgreSQL\n",
    "    financial_data['quarterly'].to_sql(\"quarterly_financials\", postgres_engine, if_exists=\"replace\", index=False)\n",
    "    financial_data['annual'].to_sql(\"annual_financials\", postgres_engine, if_exists=\"replace\", index=False)\n",
    "    financial_data['metrics'].to_sql(\"financial_metrics\", postgres_engine, if_exists=\"replace\", index=False)\n",
    "    print(f\"Saved financial data to files and PostgreSQL\")\n",
    "\n",
    "\n",
    "    # 3. News and sentiment data\n",
    "    mongo_db.drop_collection('news')\n",
    "    news_collection = mongo_db.create_collection('news')\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Company news\n",
    "        for ticker in tickers:\n",
    "            if calls_made >= 25:\n",
    "                print(\"Daily API limit reached. Please wait until tomorrow.\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Fetching company news for {ticker}\")\n",
    "            news_data = await get_news_company(session, api_key, ticker)\n",
    "            if news_data:\n",
    "                all_news.append(news_data)\n",
    "                calls_made += 1\n",
    "                # Save to local file\n",
    "                output_file = os.path.join(data_dir, \"news_data.json\")\n",
    "                with open(output_file, 'w') as f:\n",
    "                    json.dump(all_news, f, indent=4)\n",
    "                \n",
    "                \n",
    "                # Save to MongoDB\n",
    "                company = yf.Ticker(ticker)\n",
    "                company_name = company.info.get('longName', ticker)\n",
    "                  \n",
    "                news_collection.insert_one({\n",
    "                    'type': 'company_news',\n",
    "                    'ticker': ticker,\n",
    "                    'company_name': company_name,\n",
    "                    'data': news_data\n",
    "                })\n",
    "                print(f\"Saved company news for {ticker}. API calls made: {calls_made}/25\")\n",
    "                await asyncio.sleep(1)\n",
    "        \n",
    "        # Industry news\n",
    "        for topic in topics:\n",
    "            if calls_made >= 25:\n",
    "                print(\"Daily API limit reached.\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Fetching industry news for {topic}\")\n",
    "            news_data = await get_news_industry(session, api_key, topic)\n",
    "            \n",
    "            if news_data:\n",
    "                all_news.append(news_data)\n",
    "                calls_made += 1\n",
    "                # Save to local file\n",
    "                output_file = os.path.join(data_dir, \"news_data.json\")\n",
    "                with open(output_file, 'w') as f:\n",
    "                    json.dump(all_news, f, indent=4)\n",
    "                # Save to MongoDB\n",
    "                news_collection.insert_one({\n",
    "                    'type': 'industry_news',\n",
    "                    'topic': topic,\n",
    "                    'data': news_data\n",
    "                })\n",
    "                print(f\"Saved industry news for {topic}. API calls made: {calls_made}/25\")\n",
    "                await asyncio.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example Main Download Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching stock data...\n",
      "Successfully processed AAPL (Apple Inc.)\n",
      "Successfully processed MSFT (Microsoft Corporation)\n",
      "Successfully processed GOOGL (Alphabet Inc.)\n",
      "Successfully processed NVDA (NVIDIA Corporation)\n",
      "Successfully processed AMZN (Amazon.com, Inc.)\n",
      "Successfully processed JPM (JPMorgan Chase & Co.)\n",
      "Successfully processed GS (The Goldman Sachs Group, Inc.)\n",
      "Saved stock data to /Users/metedibi/Desktop/LLM_STUDIES/novus_case_study/financial_data/stock_data.csv and PostgreSQL\n",
      "Fetching company financials...\n",
      "Processing Apple Inc. (AAPL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed Apple Inc.\n",
      "Processing Microsoft Corporation (MSFT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed Microsoft Corporation\n",
      "Processing Alphabet Inc. (GOOGL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed Alphabet Inc.\n",
      "Processing NVIDIA Corporation (NVDA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed NVIDIA Corporation\n",
      "Processing Amazon.com, Inc. (AMZN)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed Amazon.com, Inc.\n",
      "Processing JPMorgan Chase & Co. (JPM)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed JPMorgan Chase & Co.\n",
      "Processing The Goldman Sachs Group, Inc. (GS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  quarterly_df['Revenue_QoQ'] = quarterly_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  annual_df['Revenue_YoY'] = annual_df['Total Revenue'].pct_change().round(4)\n",
      "/var/folders/vz/tyvljhm52ysb6jv0tv6x55pm0000gn/T/ipykernel_95288/2812751978.py:92: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  'metrics': pd.concat(metrics_data) if metrics_data else pd.DataFrame()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed The Goldman Sachs Group, Inc.\n",
      "Saved financial data to files and PostgreSQL\n",
      "Fetching company news for AAPL\n",
      "Saved company news for AAPL. API calls made: 1/25\n",
      "Fetching company news for MSFT\n",
      "Saved company news for MSFT. API calls made: 2/25\n",
      "Fetching company news for GOOGL\n",
      "Saved company news for GOOGL. API calls made: 3/25\n",
      "Fetching company news for NVDA\n",
      "Saved company news for NVDA. API calls made: 4/25\n",
      "Fetching company news for AMZN\n",
      "Saved company news for AMZN. API calls made: 5/25\n",
      "Fetching company news for JPM\n",
      "Saved company news for JPM. API calls made: 6/25\n",
      "Fetching company news for GS\n",
      "Saved company news for GS. API calls made: 7/25\n",
      "Fetching industry news for TECHNOLOGY\n",
      "Saved industry news for TECHNOLOGY. API calls made: 8/25\n",
      "Fetching industry news for FINANCIAL_MARKETS\n",
      "Saved industry news for FINANCIAL_MARKETS. API calls made: 9/25\n",
      "Fetching industry news for ECONOMY_MONETARY\n",
      "Saved industry news for ECONOMY_MONETARY. API calls made: 10/25\n"
     ]
    }
   ],
   "source": [
    "alpha_api_key = \"ME37U6ERUXI6ETIT\"\n",
    "\n",
    "# example list of company tickers \n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"NVDA\", \"AMZN\", \"JPM\", \"GS\"]\n",
    "topics = [\"TECHNOLOGY\", \"FINANCIAL_MARKETS\", \"ECONOMY_MONETARY\"]   \n",
    "\n",
    "await download_financial_data(alpha_api_key, tickers, topics)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
